\chapter{Lists, Stacks, Queues}\label{chap:linear}
Now for the most basic linear abstract data types after arrays.
In this project I reused the existing building blocks (dynamic arrays and intrusive deques)
and added a small layer of generic code templating to obtain list, stack and queue interfaces
specialized for concrete datum types such as \texttt{int}. The idea is to avoid rewriting the
same logic for each type while still getting type-specific functions like
\texttt{int\_stack\_array\_push()} or \texttt{int\_queue\_pop()}.
\section{List interface}\label{lists:interface}
Lists are implemented as a thin wrapper around the intrusive deque presented in
Chap.~\ref{chap:deques}. The list type is essentially an alias for the deque type, and the list
API is just a set of macros that forward to deque operations (push front/back, pop front/back,
first/last, empty, etc.). This way, we get a convenient “list” interface without introducing a new
data structure: all the hard work is done by the deque module.
\section{Stack interface}\label{stacks:interface}
Stacks are generated by a template header \texttt{libellul/type/stack.h}. Before including it,
the user defines:
\begin{itemize}
\item \texttt{T\_STACK\_TAG} (name tag, e.g.\ \texttt{int\_stack\_array} or
\texttt{int\_stack\_deque});
\item \texttt{T\_STACK\_ELEMENT} (element type, e.g.\ \texttt{int});
\item one backend macro: \texttt{T\_IMPL\_STACK\_ARRAY} or
\texttt{T\_IMPL\_STACK\_DEQUE}.
\end{itemize}
From this, the template generates a consistent API: \texttt{TAG\_new()},
\texttt{TAG\_delete()}, \texttt{TAG\_push()}, \texttt{TAG\_pop()}, \texttt{TAG\_top()},
\texttt{TAG\_length()}, \texttt{TAG\_is\_empty()}. I instantiated two versions for \texttt{int}:
\begin{itemize}
\item \textbf{array-based} (\texttt{int\_stack\_array}): the stack is a dynamic array, using
\texttt{array\_push}/\texttt{array\_pop} at the end;
\item \textbf{deque-based} (\texttt{int\_stack\_deque}): the stack is a deque where the back
is the top, storing each value in a small intrusive node.
\end{itemize}
Both versions are tested in \texttt{test/props/stack.c}, checking basic behaviour and LIFO
order.
\section{Queue interface}\label{queues:interface}
Queues are implemented in a similar way, via a template header \texttt{libellul/type/queue.h}.
For an \texttt{int} queue, I define:
\begin{lstlisting}[style=C]
#define T_QUEUE_TAG int_queue
#define T_QUEUE_ELEMENT int
#include <libellul/type/queue.h>
\end{lstlisting}
The template then provides \texttt{int\_queue\_new()}, \texttt{int\_queue\_delete()},
\texttt{int\_queue\_push()}, \texttt{int\_queue\_pop()}, \texttt{int\_queue\_front()},
\texttt{int\_queue\_back()}, etc. Internally, the queue is always backed by a deque: pushes
go to the back, pops remove from the front, which gives natural FIFO behaviour. The file
\texttt{test/props/queue.c} exercises this API and checks that elements come out in the same
order they were inserted.
\section{Benchmark}
To compare the two stack backends, I added a small benchmark in
\texttt{bench/bench\_stack.c}. It instantiates both \texttt{int\_stack\_array} and
\texttt{int\_stack\_deque}, then, for several sizes \(N\), measures the time needed to push
and pop \(N\) elements, averaged over a few rounds, using the standard C \texttt{clock()}
function. The program prints a simple table (size, array time, deque time) that is redirected
by the Makefile into \texttt{bench/bench\_stack.csv}. A gnuplot script
\texttt{bench/bench\_stack.plt} produces the corresponding plot.
\subsection{Observations and conclusions}
The measurements show that the array-based stack is generally faster, especially for large
\(N\), thanks to contiguous memory and cheap operations at the end of the array. The
deque-based stack has a higher overhead (extra nodes and pointer indirections), but it
integrates nicely with the intrusive deque framework used for lists and queues. In practice,
the array backend is a good default for simple stacks of primitive types, while the deque
backend is attractive when structural uniformity and intrusive linking are more important than
raw speed.